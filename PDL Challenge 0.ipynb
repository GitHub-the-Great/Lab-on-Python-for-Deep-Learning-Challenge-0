{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "import torchvision\n", "import torchvision.transforms as transforms\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from torchvision.models import resnet18\n", "from torch.utils.data import DataLoader, Subset\n", "from collections import defaultdict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_cifar10_loader(N, batch_size=128):\n", "    \"\"\" Load CIFAR-10 dataset with custom class distribution.\"\"\"\n", "    transform = transforms.Compose([\n", "        transforms.ToTensor(),\n", "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n", "    ])\n", "    dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n", "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n", "    \n", "    indices = [[] for _ in range(10)]\n", "    for idx, (_, label) in enumerate(dataset):\n", "        indices[label].append(idx)\n", "    \n", "    selected_indices = []\n", "    for i, n in enumerate(N):\n", "        selected_indices.extend(indices[i][:n])\n", "    \n", "    train_subset = Subset(dataset, selected_indices)\n", "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n", "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n", "    \n", "    return train_loader, test_loader"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def train_model(model, train_loader, criterion, optimizer, num_epochs=20):\n", "    \"\"\" Train ResNet18 model.\"\"\"\n", "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "    model.to(device)\n", "    \n", "    train_acc = []\n", "    for epoch in range(num_epochs):\n", "        correct, total = 0, 0\n", "        model.train()\n", "        for images, labels in train_loader:\n", "            images, labels = images.to(device), labels.to(device)\n", "            optimizer.zero_grad()\n", "            outputs = model(images)\n", "            loss = criterion(outputs, labels)\n", "            loss.backward()\n", "            optimizer.step()\n", "            _, predicted = outputs.max(1)\n", "            total += labels.size(0)\n", "            correct += (predicted == labels).sum().item()\n", "        \n", "        acc = 100 * correct / total\n", "        train_acc.append(acc)\n", "        print(f'Epoch {epoch+1}/{num_epochs}, Train Accuracy: {acc:.2f}%')\n", "    \n", "    return train_acc"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate_model(model, test_loader):\n", "    \"\"\" Evaluate model accuracy per class.\"\"\"\n", "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "    model.to(device)\n", "    model.eval()\n", "    class_correct = defaultdict(int)\n", "    class_total = defaultdict(int)\n", "    \n", "    with torch.no_grad():\n", "        for images, labels in test_loader:\n", "            images, labels = images.to(device), labels.to(device)\n", "            outputs = model(images)\n", "            _, predicted = outputs.max(1)\n", "            \n", "            for i in range(len(labels)):\n", "                label = labels[i].item()\n", "                class_correct[label] += (predicted[i] == label).item()\n", "                class_total[label] += 1\n", "    \n", "    per_class_accuracy = {i: 100 * class_correct[i] / class_total[i] for i in range(10)}\n", "    return per_class_accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_results(train_acc, per_class_accuracy):\n", "    \"\"\" Plot training accuracy and per-class accuracy.\"\"\"\n", "    plt.figure(figsize=(8,6))\n", "    plt.plot(train_acc, marker='o', label='Training Accuracy')\n", "    plt.xlabel(\"Epochs\")\n", "    plt.ylabel(\"Accuracy (%)\")\n", "    plt.title(\"Training Accuracy Over Epochs\")\n", "    plt.legend()\n", "    plt.show()\n", "    \n", "    plt.figure(figsize=(10,6))\n", "    sns.barplot(x=list(per_class_accuracy.keys()), y=list(per_class_accuracy.values()))\n", "    plt.xlabel(\"Class\")\n", "    plt.ylabel(\"Accuracy (%)\")\n", "    plt.title(\"Per-Class Accuracy\")\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "    # Step 1: Load and preprocess dataset\n", "    N = [4000] * 10  # Balanced dataset\n", "    train_loader, test_loader = get_cifar10_loader(N)\n", "    \n", "    # Step 2: Define ResNet18\n", "    model = resnet18(num_classes=10)\n", "    criterion = nn.CrossEntropyLoss()\n", "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n", "    \n", "    # Step 3: Train model\n", "    train_acc = train_model(model, train_loader, criterion, optimizer, num_epochs=20)\n", "    \n", "    # Step 4: Evaluate model\n", "    per_class_accuracy = evaluate_model(model, test_loader)\n", "    \n", "    # Step 6: Plot results\n", "    plot_results(train_acc, per_class_accuracy)\n", "    \n", "    # Step 5: Investigate dataset imbalance\n", "    N_imbalanced = [6000 if i == 0 else 3777 for i in range(10)]\n", "    train_loader_imbal, _ = get_cifar10_loader(N_imbalanced)\n", "    \n", "    model = resnet18(num_classes=10)\n", "    train_acc_imbal = train_model(model, train_loader_imbal, criterion, optimizer, num_epochs=20)\n", "    per_class_accuracy_imbal = evaluate_model(model, test_loader)\n", "    \n", "    plot_results(train_acc_imbal, per_class_accuracy_imbal)\n", "    \n", "    # Step 7: Modify loss function to mitigate imbalance\n", "    class_weights = torch.tensor([1/6000 if i == 0 else 1/3777 for i in range(10)], dtype=torch.float32).to(device)\n", "    weighted_criterion = nn.CrossEntropyLoss(weight=class_weights)\n", "    \n", "    model = resnet18(num_classes=10)\n", "    train_acc_weighted = train_model(model, train_loader_imbal, weighted_criterion, optimizer, num_epochs=20)\n", "    per_class_accuracy_weighted = evaluate_model(model, test_loader)\n", "    \n", "    plot_results(train_acc_weighted, per_class_accuracy_weighted)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}